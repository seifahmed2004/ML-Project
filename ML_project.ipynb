{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HehO8KMV4vh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/mhealth_raw_data.csv\")\n",
        "df\n",
        "# !kaggle datasets download -d gaurav2022/mobile-health\n",
        "\n",
        "\n",
        "# !unzip mobile-health.zip\n",
        "\n",
        "\n",
        "# df = pd.read_csv('mhealth_raw_data.csv')"
      ],
      "metadata": {
        "id": "iHgv6rrUV5jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df.iloc[50000:50100]\n",
        "print(df_subset)"
      ],
      "metadata": {
        "id": "AVzM8Hhl1-SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "X = df_subset.drop('subject',axis=1)\n",
        "sns.heatmap(X)\n"
      ],
      "metadata": {
        "id": "qxfCbfNTly3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization of sample data points\n",
        "print(\"Sample data points:\")\n",
        "print(df.head())\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(df['aly'], label='Feature 1')\n",
        "plt.plot(df['ary'], label='Feature 2')\n",
        "\n",
        "plt.title('Sample Data Points')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7M2IEIRhYGnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:, -1]"
      ],
      "metadata": {
        "id": "m-SqMrtMYydB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle = True, random_state=0)\n",
        "\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)\n"
      ],
      "metadata": {
        "id": "rvBw1WPDaTH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()\n"
      ],
      "metadata": {
        "id": "zybfG84kf6rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "LK128zjJgLRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_duplicates = df.drop_duplicates()\n",
        "print(\"Original DataFrame shape:\", df.shape)\n",
        "print(\"DataFrame shape after removing duplicates:\", df_no_duplicates.shape)"
      ],
      "metadata": {
        "id": "LKu98m5XgRYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (f\"training set size: {X_train.shape[0]} samples \\ntest set size: {X_test.shape[0]} samples \")"
      ],
      "metadata": {
        "id": "84P2oNGlgakO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "l7yuzDxRgv2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.DataFrame(X_train)\n",
        "X_train = X_train.dropna()\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_train = y_train.dropna()"
      ],
      "metadata": {
        "id": "5UFfVtLH6_dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.geeksforgeeks.org/k-nearest-neighbor-algorithm-in-python/\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create an instance of KNeighborsClassifier with k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Train the model using your training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "W34LSrslj3U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn"
      ],
      "metadata": {
        "id": "tzqCtoMAUc3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fYW5tCI6n27e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class svm_hard_margin:\n",
        "\n",
        "  weights = []\n",
        "  bias = 0\n",
        "\n",
        "  def fit(self, x, y, learning_rate, epochs):\n",
        "    n_samples, n_features = x.shape\n",
        "    self.weights = np.zeros(n_features)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        for j in range(n_samples):\n",
        "            condition = y[j] * (np.dot(x[j], self.weights) + self.bias) >= 1\n",
        "            if not condition:\n",
        "                # Misclassification, update weights and bias\n",
        "                self.weights += learning_rate * (x[j] * y[j] - 2 * 1/epoch * self.weights)\n",
        "                self.bias += learning_rate * y[j]\n",
        "\n",
        "  def predict(self, x):\n",
        "    predictions = np.dot(x, self.weights) + self.bias\n",
        "    predictions = np.sign(predictions)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "I7JCjF1Wj_7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "# y_train = y_train[:316684]\n",
        "# svm = SVC(C=10, kernel='rbf')\n",
        "# svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "wnbgadaj8eT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_decision_regions(X_train, y_train, clf=svm, legend=2)\n",
        "\n",
        "# plt.title('SVM')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "PSD0Eer_-pU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "OjOzSdsK-rks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3, random_state=1)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=1)\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
      ],
      "metadata": {
        "id": "WCo1p2c2FLWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1022/32"
      ],
      "metadata": {
        "id": "t6s-KLoVISsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense #makes summation, activation\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import SGD, Adam"
      ],
      "metadata": {
        "id": "3NoW6R1GIpJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(10,)), #vector\n",
        "    Dense(5, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])"
      ],
      "metadata": {
        "id": "LF3-1rBFIWG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "x7pxAit1IY01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess the data (these are NumPy arrays)\n",
        "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
        "\n",
        "y_train = y_train.astype(\"float32\")\n",
        "y_test = y_test.astype(\"float32\")\n",
        "\n",
        "# Reserve 10,000 samples for validation\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n"
      ],
      "metadata": {
        "id": "dkfeSoU_KB-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Fit model on training data\")\n"
      ],
      "metadata": {
        "id": "FVM2hFUtVqh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r_x1nX3ZI-np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=2,\n",
        "    # We pass some validation for\n",
        "    # monitoring validation loss and metrics\n",
        "    # at the end of each epoch\n",
        "\n",
        "    validation_data=(x_val, y_val),\n",
        ")\n"
      ],
      "metadata": {
        "id": "nvNuRUIIIuyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have your input data X and target data y\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shapes of the training and testing sets\n",
        "print(\"Training set shapes - X_train: {}, y_train: {}\".format(X_train.shape, y_train.shape))\n",
        "print(\"Testing set shapes - X_test: {}, y_test: {}\".format(X_test.shape, y_test.shape))\n"
      ],
      "metadata": {
        "id": "VdfTu8IiIw9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_adj = X_test[:5000]\n",
        "y_test_adj = y_test[:5000]"
      ],
      "metadata": {
        "id": "XX8XqzFjJ-9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.evaluate(X_test_adj, y_test_adj)"
      ],
      "metadata": {
        "id": "0qId9LRXLm_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mH6ugIMrL_qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3WR0D-IINPKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define sigmoid function\n",
        "def sigmoid(z):\n",
        "    #output > 0.5 when z is positive\n",
        "    #output < 0.5 when z is negative\n",
        "    return 1/(1+np.exp(-z)) # Output in range [0,1]"
      ],
      "metadata": {
        "id": "E1t72KKYPinZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= np.arange(-20,20)\n",
        "y= np.round(sigmoid(x),2)"
      ],
      "metadata": {
        "id": "61mztGYRgEtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x, y)\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Logistic/sigmoid function applied')"
      ],
      "metadata": {
        "id": "NZnJHL-rgGP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "7Pn3-_RwgH2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "fV5-h9iRgMG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['alx'].value_counts()"
      ],
      "metadata": {
        "id": "RnOB9wlngOxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('subject',axis=1)\n",
        "y = df['subject']\n",
        "# Convert all columns in X to integers\n",
        "# X = X.astype(int)\n",
        "\n",
        "# # Convert y to integers\n",
        "# y = y.astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101, shuffle=True)"
      ],
      "metadata": {
        "id": "WcjxxJn-gTBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "id": "WFfsI3AogX4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "Am6pWQ7RgpHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "EOaYYcKZg3Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "6cwvRmC8kn4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from mlxtend.preprocessing import shuffle_arrays_unison\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "\n",
        "from sklearn.svm import SVC\n"
      ],
      "metadata": {
        "id": "A2yNi6jFksaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['aly', 'ary']].values\n",
        "y = df['subject'].values\n",
        "\n",
        "X, y = shuffle_arrays_unison(arrays=[X, y], random_seed=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "\n",
        "X = scaler.transform(X)\n",
        "X_train, y_train = X[:100], y[:100]\n",
        "X_test, y_test = X[100:], y[100:]\n"
      ],
      "metadata": {
        "id": "0PCFFcwwprMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "# scores = cross_val_score(clf, X, y, cv=5)\n",
        "# scores"
      ],
      "metadata": {
        "id": "aKUZNHbQpGZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7O5_7Mc6pfFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}